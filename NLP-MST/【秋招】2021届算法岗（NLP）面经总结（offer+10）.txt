https://zhuanlan.zhihu.com/p/225587871
一、聊项目
根据我的经验，聊项目大致分为两种。

一种是面试官没来得及详细看你的简历，只看了你项目的标题，这时他会挑一个他比较感兴趣的标题，让你详细的介绍一下。这种问题需要你把做过的项目能通过STAR原则叙述出来，即有“广”度的把项目介绍完整。问法如下：

说一个你认为做的比较好/有成就感/深入的项目。
另一种是面试官提前看过你的项目描述/听你完整介绍完了项目，过程中产生一些疑问想与你确认。这种问题需要你能够尽可能的回忆起项目的每个细节，有“深”度的思考为什么当初选择这样做、遇到的困难以及你的解决方法。问题如下：

【大厂算法】项目的数据来源？
【大厂算法】项目的输入输出是什么？
【大厂算法】垂搜还是泛搜，举几个query的例子？
【大厂算法】title的召回和排序工作怎么做的？
【大厂算法】为什么字符串匹配要用前缀树实现，哈希表不就可以吗？
【大厂算法】构建前缀树的词表是什么？
【大厂算法】文本分类有没有考虑用分词处理？
【大厂算法】分词器把词的粒度分的太小，和字特征的效果差不多怎么解决？
【大厂算法】你这些工作的性能是怎么评估的？
【大厂算法】文本分类是怎么做的？
【大厂算法】文本分类的规则代码有多少条规则？
【大厂算法】实词粒度的语义匹配是怎么做的？
【大厂算法】分词和依存关系分析的算子是哪里的？
【大厂算法】项目中你最满意的模块是哪一个？原因？
【大厂算法】利用依存关系分析提取主谓宾的具体过程是怎样的？
【大厂算法】这个项目遇到的难点是什么，你怎么解决的？
【大厂算法】重新用模型方法做你这个项目你会怎么设计？
【小公司算法】项目中你最满意的部分是什么？
【小公司算法】区分度指标81%是怎么计算的？
【文本分类Top1%】用Bert的时候踩过什么坑吗？
【文本分类Top1%】Bert的后接结构是怎么做的？
【文本分类Top1%】EDA和回译是怎么做的？
【文本分类Top1%】数据清洗和伪标签是怎么做的？
【文本分类Top1%】模型融合是怎么做的？
【文本分类冠军】多少个队伍参赛？团队成员分工？
【文本分类冠军】模型融合怎么做的？
【文本分类冠军】调参是怎么做的？
【文本分类冠军】改进交叉熵损失函数怎么做的？
【文本分类冠军】Tensorflow实现RNN的过程是什么？
【文本分类冠军】为什么用RNN而不是CNN？
【文本分类冠军】第一版模型的性能是多少？
【知识库问答项目】为什么用Bert + BiLSTM + CRF这种结构？（子问题1：为什么不直接用Bert + CRF？子问题2：为什么不直接用BiLSTM + CRF？）
【知识库问答项目】为什么用CRF，不用HMM？
二、聊基础
基础知识的考查与你的简历上的关键字强相关，你也可以在其他环节自己给自己挖坑，来展示你学过的基础知识。另外，要有一个你特别特别熟悉的模型，并准备一段关于它的描述，因为很多时候，面试官会开放性的问：说一个你比较熟悉的传统机器学习模型吧，哪个都行。我遇到的问题如下：

【编程语言】对比一下你学过的语言
【编程语言】面向对象编程的几个关键特性？
【Python】pandas，输出年龄大于10的数据？
【Python】浅拷贝与深拷贝？
【Python】垃圾回收机制？
【Python】Python的三元运算符？
【Java】java接口与抽象类的区别？
【数据库】数据库的第一、第二、第三范式。
【数据库】表A有5条数据，表B有8条数据：题目1：A表left join 表B，最少是几条数据，最多是几条数据；题目2：A表 inner join表B，最少是几条数据，最多是几条数
【数据结构与算法】数组和链表的对比？从存储以及各种操作的时间复杂度角度？
【数据结构与算法】如何判断一个链表有没有环？
【数据结构与算法】栈和队列简单说一下？
【数据结构与算法】图怎么遍历？
【数据结构与算法】常见排序算法的稳定性？
【数据结构与算法】快排的思想？
【数据结构与算法】快排的最好、最坏、平均时间复杂度？
【数据结构与算法】基数排序的适用性？
【数据结构与算法】并查集的原理是什么？
【数据结构与算法】动态规划的思想是什么？
【概率统计】如果解决abtest的自然增长因素的影响？
【概率统计】假设检验的原理？
【排列组合】M * N的网格，一共有多少的矩形？
【特征工程】卡方检验的原理？
【特征工程】其他特征选择方法？
【特征工程】L1正则化怎么进行优化？
【特征工程】对于刚拿到的一个数据，会进行哪些处理？
【机器学习】机器学习的概念和做机器学习项目的流程？
【机器学习】挑一个你熟悉的传统机器学习算法讲一下。
【机器学习】LR模型的优缺点以及适用性？
【机器学习】LR模型里面有共线性的问题怎么解决？
【机器学习】为什么LR模型的用交叉熵损失函数而不是均方误差？
【机器学习】介绍SVM模型以及它的核函数。
【机器学习】SVM的高斯核函数公式是什么？为什么解决非线性问题一定要用核函数？
【机器学习】SVM的支持向量是什么？
【机器学习】SVM可以用梯度下降法优化吗？
【机器学习】FM的原理（如何学习没有出现过的组合特征）？
【机器学习】PCA的原理是什么？
【机器学习】KNN和K-means的原理与对比？
【机器学习】EM算法，E步在做什么、M步在做什么？
【机器学习】树模型常见的loss是什么？（树模型怎么做特征选择？）
【机器学习】RF是用来降低方差还是学习残差？
【机器学习】LGB/XGB叶子结点的权重是怎么计算出来的？
【机器学习】XGBoost里面正则化项是什么？
【机器学习】XGBoost防止过拟合的方法？
【机器学习】LightGBM怎么调参可以防止过拟合？
【机器学习】树集成模型，层数少+树多，与层数多+树少，哪个更能防止过拟合？
【机器学习】CRF的模型的原理是什么？
【机器学习】CRF有哪两个特征函数？模型的形式是怎样的？
【机器学习】BiLSTM + CRF中的两个特征函数的值是怎么得到的？
【机器学习】CRF的损失函数是什么？
【机器学习】超参数搜索方法了解哪些？
【机器学习】EDA（Easy Data Augmentation）是什么？
【机器学习】类别不平衡的解决办法？
【过拟合欠拟合】防止过拟合的方法？
【过拟合欠拟合】L1L2正则化的原理？对比。
【过拟合欠拟合】Dropout怎么解决训练和预测输入不一致的问题。
【模型评估】准确率和精确率的区别？
【模型评估】F1值是怎么计算的？为什么用F1计算？
【模型评估】F2值是什么，Fbeta怎么计算？
【模型评估】ROC的画法和使用场景有哪些？
【模型评估】AUC的计算方法？
【模型融合】模型融合的方法有哪些？
【深度学习与NLP】对NLP领域的理解？
【深度学习与NLP】中文与其他语种的在NLP任务中的不同点？
【深度学习与NLP】常见激活函数以及它们的特点？
【深度学习与NLP】说说知道的优化器？
【深度学习与NLP】sgd和Adam的公式？
【深度学习与NLP】梯度消失和梯度爆炸的原理和解决方法？
【深度学习与NLP】 Word2Vec的原理？
【深度学习与NLP】 Doc2Vec的原理？
【深度学习与NLP】Word2Vec里面关于加速计算的技巧？
【深度学习与NLP】层次化softmax的时间复杂度是多少？
【深度学习与NLP】文本长度不一致怎么处理？
【深度学习与NLP】RNN对输入长度不一致的文本怎么处理？
【深度学习与NLP】LSTM有哪三个门？
【深度学习与NLP】手写LSTM公式？
【深度学习与NLP】LSTM解决了RNN的什么问题？为什么？
【深度学习与NLP】对Attention的理解？
【深度学习与NLP】BERT的原理是什么？
【深度学习与NLP】RoBERTa的原理是什么？
【深度学习与NLP】BERT用字粒度和词粒度的优缺点有哪些？
【深度学习与NLP】BERT的Encoder与Decoder掩码有什么区别？
【深度学习与NLP】BERT用的是Tranformer里面的encoder还是decoder？
【深度学习与NLP】BERT和BiLSTM的区别有哪些？
【深度学习与NLP】multi-head attention最后除以一个dk的作用？
【深度学习与NLP】 BERT的softmax掩码怎么做的，为什么这么做？
【深度学习与NLP】 Transformer里面的position encoding怎么做的？
【深度学习与NLP】NSP任务为什么没有用？
【深度学习与NLP】单独用BiLSTM做NER有什么弊端？
【深度学习与NLP】 SimNet网络的结构？
【深度学习与NLP】深度学习单卡的训练，怎么修改代码变成多卡。
【深度学习与NLP】深度学习和传统机器学习之间对比？
【深度学习与NLP】NLP发展面临的阻碍和挑战？
【其他】Elastic Search的原理？
三、场景题
场景题一般是看你知识和经验的迁移能力，这个地方没有什么对错，能多想几个方案就多说几个。（我把一些与专业知识相关的开放题也算作了场景题）

单用一层简单的全连接神经网络可以实现Attention的效果吗？优缺点是什么？
电商网站，怎么实现用户query和商品的语义匹配？举个例子，用户输入“3mm”，代表耳机插孔的尺寸，怎么基于“3mm”对相关商品进行检索？
N个人，10种职业，知道每个人的薪水但不知道他们的职业，现在有一个人，知道他的薪水，问怎么找出他的所有同行？
商品做一个基于相似度的推荐，商品库很大，怎么推荐TopK个商品。另外，动态追加商品的情况怎么设计？
共享单车的场景，用户报告的故障，有图像、结构化数据、文字等等，以及用户信息、地理信息，怎么去判断故障是否为真？
一个链表，长度未知（设为n），只能遍历一次，取出k个元素，使得每一个元素取到的可能性一样？（蓄水池抽样）
从一个数据流取出n个数据，保证每个数据被抽到的概率相同，问抽取策略？（蓄水池抽样）
网易云音乐怎么去决策一个版权该不该买？
四、手撕算法
手撕算法是如今rd岗位面试的必备环节，如果时间紧迫，操作系统、计算机组成原理、计算机网络可以不复习，但是数据结构和算法一定要复习。常见的数据结构、它的特点、它的操作以及操作的复杂度，要能烂熟于心。常见的算法与算法思想，如二分、排序、递归、回溯、搜索、动态规划、贪心、字符串匹配，要多回顾。** 标记了出现多次的题目。

【数组】41. 缺失的第一个正数
【数组】347. 前 K 个高频元素
【数组】334. 递增的三元子序列
【字符串】468. 验证IP地址
【字符串】基于辞典的正向最长匹配分词
【二分查找】69. x 的平方根（迭代和递归两种方法实现）**
【二分查找】34. 在排序数组中查找元素的第一个和最后一个位置
【栈 + 队列】剑指 Offer 09. 用两个栈实现队列
【栈 + 队列】面容评分系统写成一个类，满足三个函数，（1）按时间戳添加脸和脸的分数（2）输出24小时中的平均脸（3）输出24小时中的最大脸。ps：后续问了1. 如果脸的存储要求很大怎么办？2. 测试用例怎么写
【单调栈】Leetcode 503. 下一个更大元素 II
【链表】142. 环形链表 II
【链表】138. 复制带随机指针的链表
【链表】25. K 个一组翻转链表 **
【树】199. 二叉树的右视图
【树】 剑指 Offer 28. 对称的二叉树
【树】951. 翻转等价二叉树
【迭代】415. 字符串相加包含小数
【递归】将嵌套列表变为嵌套元组
【动态规划】300. 最长上升子序列 ****
【动态规划】1143. 最长公共子序列输出最长公共序列
【动态规划】5. 最长回文子串
【动态规划】 887. 鸡蛋掉落
【图】 200. 岛屿数量
【图】查找同义词集
【图】拓扑排序
【图】输出子图的拓扑排序
【图】给定一组等式与不等式字符串，判断是否合法，如"a=b","b=c","a!=c"是非法的。
【机器学习】现有100条训练数据20个特征，特征都是一些分数，设计实现一个4分类算法。
【计算机视觉】非极大值抑制算法（non-maximum suppression）
五、聊人生
聊人生一般出现在技术三面、或HR面，是和面试官输出你的价值观、职业规划、其他过往经历。** 标记了需要且必须准备的一些问题。

父母做什么职业的？
男朋友情况？多大？什么专业？offer情况？
管理科学与工程是个什么专业？
在线期间的成绩如何？绩点/排名？
四六级成绩？
奖学金情况？
大学期间有什么专业课？
研究生期间有什么专业课？某一个课程都讲了什么内容（如运筹学和优化方法）？
硕士期间的研究方向是什么？
大学期间的规划是什么？
今后的职业规划是什么？为什么这么规划？**
选择一份工作最看重的三点？**
都投了哪些公司？都收到了哪些offer？**
期望的薪资是多少？怎么定出来的？**
对自己即将进入的行业和职业有什么看法？
对我们公司有什么了解？**
实习的部门做个简单的介绍？
实习部门一共多少人，实习生多少？
实习最喜欢的部分和最不喜欢的部分？
你更喜欢做研究型的算法还是业务型的？
平时学习是自己学还是和同学交流？周围氛围怎么样？
为什么从机器学习这个大范围选择NLP？
感觉自己能多久能搞定c++？
比赛取得冠军的关键因素是什么？
比赛取得冠军的收获是什么？
优缺点是什么？缺点准备如何改正？**
觉得自己是一个什么样的人？（=优缺点）
用三个形容词形容自己？（=优缺点）
为什么说自己有这样的优点，出发点是什么？举例子？
平时都怎么学习，包括专业知识和业余知识？
英语怎么样？日常对话可以吗？老友记讲了啥？？？
最有成就感的事情？
最痛苦的事？事后怎么恢复？为什么说这个是最痛苦的事？
遭受最大的挫折是什么？**
遇见挫折之后通常有什么表现？
有什么坚持下去的事情？
有什么放弃了的事情？
有什么遗憾的事情？
有没有什么比较丧的事？
觉得压力比较大的事情？
投入时间最多的事情？
主动争取，然后取得好结果的事情？
殚精竭虑、废寝忘食的事情？
团队合作愉快和不愉快的事情？
团队合作中遇见冲突，解决了的事情？**
都读过哪些书，列举出10本？
有没有被要求做过不认可的事情？
最不能忍受的室友的事情？
做事比较快但不细致，还是做事比较慢但是很认真？
出去玩一般是别人等你收拾，还是你等别人收拾？
六、总结
秋招共投递了70余家，基本全都是互联网公司，少数银行、研究所。

很荣幸得到微软亚洲研究院RSDE岗位的面试机会，并通过了3个小时的Coding面，但Research面挂了。国内互联网头部公司阿里（A）和腾讯（T）没有给面试机会。还在泡池子的有360，华为没给发offer，但HR在微信上问了意向被我拒绝了，还有一些面试面到一半推掉了。一共面试了50多场，明确挂掉的只有6-7场，面的公司基本都拿到了offer。这说明面试通过本身是不难的，只要认真准备、正常发挥就可以保证通过，难的是你要花很长时间丰富自己的实践经历以通过简历筛选，并和其他竞争者一起焦急地等待排序，排序多多少少有些运气的成分。
由于2020年的疫情，很多公司都采取线上面试的方式，面试体验都还不错。总体上体验最好的是虾皮与微软。体验好的表现是，面试官会认真听你表达，想主动去理解你做的东西，肯定你项目的价值，然后在手撕代码的时候引导你走向正确的思路，基于他对你的判断逐渐增加难度。如果直接出一道Leetcode原题，然后放着你写，最后像批卷子一样告诉你，你做的对或不对，就会觉得自己很不被尊重。比如快手面试的时候，面试官小姐姐出了一道25. K 个一组翻转链表，其中包括反转链表这个函数。刷题的人都知道，反转链表闭着眼睛都能写出来。我用自己惯用的思路写出来了，面试完后自测是通过的。但是当时面试的时候小姐姐看不懂我的思路，并且没有给我机会让我解释我的思路，就把我给挂了。相反，头条的面试官出了一道5. 最长回文子串，当时我刷题复习的时候就有和动态规划不一样的思路，我没在题解中看到过。面试官看到我的解法先是表示怀疑，然后让我测了两个例子通过了，再接着给我机会解释我的思路，其间他也一直努力尝试理解，最后他终于听懂了，还截图说要和同事讨论一下。这就让人觉得很开心。

回顾自己准备算法岗求职的经历，觉得很充实，但也很焦虑。当时看到师兄师姐们找算法、数据挖掘岗位时艰难的处境，预想到自己明年只会难上+难，一度想把目标换成数据分析或者后端。但我偏偏又是一个比较刚的人，那个时候还只会一些机器学习的模型，只能推导公式，做做简单的比赛。在思考了两个晚上以后，我决定走出舒适圈，把眼光定位到更需深入钻研的领域nlp，第二天就拖满分男友帮忙打印好了cs224n的PPT，并且定好了要做什么项目提高自己的实战能力。因为小时候我就明白一个道理，只有你不断去尝试理解你特别不懂的东西，你才能更加轻松的去理解一个你有点不懂的东西，理解力都是遇强则强的，所以我选择了冒一个风险自己瞎搞nlp。整个假期包括过年也就休息了两、三天，其他时间都在看课程、做比赛、刷题。做选择的过程和人的个性有关，有的人就喜欢求稳，有些人就喜欢冒风险。其实怎么选都好，重点是要停止焦虑，着手做事情。适当规划，稳妥执行。

最后，总结一下准备秋招时应该注意的地方和应该保持的心态。首先，知己知彼。选好坐标系，知道竞争同岗位的人都在做什么、做到什么程度，但又不要太在意别人取得的成就，人与人之间的做事节奏、质变方式还有运气都是不同的。其次，抓住主要矛盾。没有比赛就去做比赛，没有实习就去实习，怕手撕就去刷题。解决一个主要矛盾得来的快感要大于解决一堆次要矛盾。最后，好事多磨。早拿offer不一定是一件好事。只要有机会，就去面，好好面。无论大家都在给你贩卖怎样的焦虑，说什么秋招6月就开始了，有人7月就拿offer了，不要听这些话。至少我自己11月份还在面头条，身边也很多在面互联网。秋招虽到但迟，没你想象中结束的那么快。